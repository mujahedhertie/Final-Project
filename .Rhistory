rm(list = ls())
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Collaborative Research Project
# Creating the Dataset
# Johannes Schulz-Knappe
# Update 16 May 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
## 1.1 Clear the environment
rm(list = ls())
## 1.2 Load packages for dataset creation
# Create vector of used packages
packages <- c('repmis', 'rvest', 'plyr', 'rio', 'xlsx')
# Install packages that are not already installed
for (p in packages) {
if (p %in% installed.packages()[,1]) require(p, character.only=TRUE)
else {
install.packages(p)
require(p, character.only=TRUE)
}
}
rm(p)
# Load packages
loaded <- lapply(packages, require, character.only = TRUE)
rm(loaded)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
## 1.4 Create bibTeX file for the used packages
LoadandCite(packages, file = 'Packages1.bib')
rm(packages)
#-----------------------------------------#
# 2. Run gathering and cleaning R files   #
#-----------------------------------------#
# Dynamically run R files in this order
## 2.1 Electoral data gathering
source("data_gathering/election_data_gathering.R")
## 2.2 Structural data gathering
source("data_gathering/structural_data_gathering.R")
## 2.3 Electoral data cleaning
source("data_cleaning/election_data_cleaning.R")
## 2.4 Structural data cleaning
source("data_cleaning/structural_data_cleaning.R")
#-----------------------------------------#
# 3. Merge the data                       #
#-----------------------------------------#
# Merge the data into the final data frame
Data <- merge(data.election, size, "ID")
Data <- merge(Data, edu, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, refugee, "ID")
Data <- merge(Data, debt, "ID")
# Remove used data frames
rm(data.election)
rm(size)
rm(edu)
rm(unemp)
rm(gdp)
rm(refugee)
rm(debt)
View(Data)
# Divide vote.AfD by 100 in order to enable beta regression
Data$vote.AfD.prcnt <- Data$vote.AfD/100
# Save Data as file in repository
save(Data, file = "Data_new.Rda")
type$district.type[grep('Kreisfreie Stadt', type$district.name)] <- 1
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
## 1.1 Clear the environment
rm(list = ls())
## 1.2 Load packages for dataset creation
# Create vector of used packages
packages <- c('repmis', 'rvest', 'plyr', 'rio', 'xlsx')
# Install packages that are not already installed
for (p in packages) {
if (p %in% installed.packages()[,1]) require(p, character.only=TRUE)
else {
install.packages(p)
require(p, character.only=TRUE)
}
}
rm(p)
# Load packages
loaded <- lapply(packages, require, character.only = TRUE)
rm(loaded)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
## 1.4 Create bibTeX file for the used packages
LoadandCite(packages, file = 'Packages1.bib')
rm(packages)
#-----------------------------------------#
# 2. Run gathering and cleaning R files   #
#-----------------------------------------#
# Dynamically run R files in this order
## 2.1 Electoral data gathering
source("data_gathering/election_data_gathering.R")
## 2.2 Structural data gathering
source("data_gathering/structural_data_gathering.R")
## 2.3 Electoral data cleaning
source("data_cleaning/election_data_cleaning.R")
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Collaborative Research Project
# Structural Data Cleaning
# Johannes Schulz-Knappe
# Update 16 May 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
# Run "1_Data.R" for workspace preparation
#-----------------------------------------#
# 2. Cleaning structural data             #
#-----------------------------------------#
## 2.1 District size
# Delete unnecessary columns
size <- size_raw[, c(2, 4)]
# Rename columns
names(size) <- c("ID", "district.size")
# Convert ID to numeric
size$ID <- as.numeric(as.character(size$ID))
## 2.2 Education
# Delete unnecessary columns
edu <- edu_raw[, c(2, 4, 6, 14)]
# Rename columns
names(edu) <- c("ID", "school.leaver", "nodegree", "abitur")
# Convert ID to numeric
edu$ID <- as.numeric(as.character(edu$ID))
# Create nodegree.ratio
edu$nodegree.ratio <- edu$nodegree/edu$school.leaver*100
# Create abitur.ratio
edu$abitur.ratio <- edu$abitur/edu$school.leaver*100
# Delete used columns
edu$nodegree      <- NULL
edu$abitur        <- NULL
edu$school.leaver <- NULL
# Remove raw data from environment
rm(edu_raw)
## 2.3 Unemployment rate
# Keep necessary columns
unemp <- unemp_raw[, c(2, 12)]
# Delete unnecessary rows
unemp <- unemp[-c(1:9), ]
# Rename columns
names(unemp) <- c("ID", "unempl.rate")
# Convert variables
unemp$ID <- as.numeric(as.character(unemp$ID))  # convert ID to numeric
unemp$unempl.rate <- as.character(unemp$unempl.rate)  # convert unempl.rate to character
unemp$unempl.rate <- gsub(",", ".", x = unemp$unempl.rate)  # replace commas with periods
unemp$unempl.rate <- as.numeric(unemp$unempl.rate)  # convert unempl.rate to numeric
# Remove raw data from environment
rm(unemp_raw)
## 2.4 GDP per capita
# Delete unnecessary columns
gdp <- gdp_raw[, c(2, 6)]
# Rename columns
names(gdp) <- c("ID", "GDP.capita")
# Convert variables
gdp$ID <- as.numeric(as.character(gdp$ID))  # Convert ID to numeric
gdp$GDP.capita <- as.character(gdp$GDP.capita)  # convert GDP.capita to character
gdp$GDP.capita <- gsub(",", ".", x = gdp$GDP.capita)  # replace commas with periods
gdp$GDP.capita <- as.numeric(gdp$GDP.capita)  # convert GDP.capita to numeric
gdp$GDP.capita <- gdp$GDP.capita/1000 # divide by thousand for better readability
# Remove raw data from environment
rm(gdp_raw)
## 2.5 Number of asylum seekers
# Keep necessary columns
refugee <- refugee_raw[, c(2, 4)]
# Rename columns
names(refugee) <- c("ID", "n.refugees")
# Remove raw data from environment
rm(refugee_raw)
## 2.6 District public debt
# Keep necessary columns
debt <- debt_raw[, c(2, 4)]
# Rename columns
names(debt) <- c("ID", "public.debt")
# Remove raw data from environment
rm(debt_raw)
type <- size_raw[, c(2, 3)]
type$district.type <- 0
type$district.type[grep('Kreisfreie Stadt', type$district.name)] <- 1
# Remove raw data from the environment
rm(size_raw)
names(type) <- c("ID", "district.name", "district.type")
type$district.name <- NULL
#-----------------------------------------#
# 3. Merge the data                       #
#-----------------------------------------#
# Merge the data into the final data frame
Data <- merge(data.election, size, "ID")
Data <- merge(Data, edu, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, refugee, "ID")
Data <- merge(Data, debt, "ID")
Data <- merge(Data, type, "ID")
View(debt)
debt <- debt/1000
View(debt)
Data <- merge(data.election, size, "ID")
Data <- merge(Data, edu, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, refugee, "ID")
Data <- merge(Data, debt, "ID")
Data <- merge(Data, type, "ID")
rm(data.election)
rm(size)
rm(edu)
rm(unemp)
rm(gdp)
rm(refugee)
rm(debt)
rm(type)
rm(list = ls())
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Collaborative Research Project
# Creating the Dataset
# Johannes Schulz-Knappe
# Update 16 May 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
## 1.1 Clear the environment
rm(list = ls())
## 1.2 Load packages for dataset creation
# Create vector of used packages
packages <- c('repmis', 'rvest', 'plyr', 'rio', 'xlsx')
# Install packages that are not already installed
for (p in packages) {
if (p %in% installed.packages()[,1]) require(p, character.only=TRUE)
else {
install.packages(p)
require(p, character.only=TRUE)
}
}
rm(p)
# Load packages
loaded <- lapply(packages, require, character.only = TRUE)
rm(loaded)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
## 1.4 Create bibTeX file for the used packages
LoadandCite(packages, file = 'Packages1.bib')
rm(packages)
#-----------------------------------------#
# 2. Run gathering and cleaning R files   #
#-----------------------------------------#
# Dynamically run R files in this order
## 2.1 Electoral data gathering
source("data_gathering/election_data_gathering.R")
## 2.2 Structural data gathering
source("data_gathering/structural_data_gathering.R")
## 2.3 Electoral data cleaning
source("data_cleaning/election_data_cleaning.R")
## 2.4 Structural data cleaning
source("data_cleaning/structural_data_cleaning.R")
#-----------------------------------------#
# 3. Merge the data                       #
#-----------------------------------------#
# Merge the data into the final data frame
Data <- merge(data.election, size, "ID")
Data <- merge(Data, edu, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, refugee, "ID")
Data <- merge(Data, debt, "ID")
Data <- merge(Data, type, "ID")
# Remove used data frames
rm(data.election)
rm(size)
rm(edu)
rm(unemp)
rm(gdp)
rm(refugee)
rm(debt)
rm(type)
# Save Data as file in repository
save(Data, file = "Data_new.Rda")
View(Data)
rm(list = ls())
## 1.2 Load packages for dataset creation
# Create vector of used packages
packages <- c('repmis', 'rvest', 'plyr', 'rio', 'xlsx')
# Install packages that are not already installed
for (p in packages) {
if (p %in% installed.packages()[,1]) require(p, character.only=TRUE)
else {
install.packages(p)
require(p, character.only=TRUE)
}
}
rm(p)
# Load packages
loaded <- lapply(packages, require, character.only = TRUE)
rm(loaded)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
## 1.4 Create bibTeX file for the used packages
LoadandCite(packages, file = 'Packages1.bib')
rm(packages)
#-----------------------------------------#
# 2. Run gathering and cleaning R files   #
#-----------------------------------------#
# Dynamically run R files in this order
## 2.1 Electoral data gathering
source("data_gathering/election_data_gathering.R")
## 2.2 Structural data gathering
source("data_gathering/structural_data_gathering.R")
source("data_cleaning/election_data_cleaning.R")
View(data.election)
# Delete unnecessary columns
size <- size_raw[, c(2, 4)]
# Rename columns
names(size) <- c("ID", "district.size")
# Convert ID to numeric
size$ID <- as.numeric(as.character(size$ID))
## 2.2 Education
# Delete unnecessary columns
edu <- edu_raw[, c(2, 4, 6, 14)]
# Rename columns
names(edu) <- c("ID", "school.leaver", "nodegree", "abitur")
# Convert ID to numeric
edu$ID <- as.numeric(as.character(edu$ID))
# Create nodegree.ratio
edu$nodegree.ratio <- edu$nodegree/edu$school.leaver*100
# Create abitur.ratio
edu$abitur.ratio <- edu$abitur/edu$school.leaver*100
# Delete used columns
edu$nodegree      <- NULL
edu$abitur        <- NULL
edu$school.leaver <- NULL
# Remove raw data from environment
rm(edu_raw)
## 2.3 Unemployment rate
# Keep necessary columns
unemp <- unemp_raw[, c(2, 12)]
# Delete unnecessary rows
unemp <- unemp[-c(1:9), ]
# Rename columns
names(unemp) <- c("ID", "unempl.rate")
# Convert variables
unemp$ID <- as.numeric(as.character(unemp$ID))  # convert ID to numeric
unemp$unempl.rate <- as.character(unemp$unempl.rate)  # convert unempl.rate to character
unemp$unempl.rate <- gsub(",", ".", x = unemp$unempl.rate)  # replace commas with periods
unemp$unempl.rate <- as.numeric(unemp$unempl.rate)  # convert unempl.rate to numeric
# Remove raw data from environment
rm(unemp_raw)
## 2.4 GDP per capita
# Delete unnecessary columns
gdp <- gdp_raw[, c(2, 6)]
# Rename columns
names(gdp) <- c("ID", "GDP.capita")
# Convert variables
gdp$ID <- as.numeric(as.character(gdp$ID))  # Convert ID to numeric
gdp$GDP.capita <- as.character(gdp$GDP.capita)  # convert GDP.capita to character
gdp$GDP.capita <- gsub(",", ".", x = gdp$GDP.capita)  # replace commas with periods
gdp$GDP.capita <- as.numeric(gdp$GDP.capita)  # convert GDP.capita to numeric
gdp$GDP.capita <- gdp$GDP.capita/1000 # divide by thousand for better readability
# Remove raw data from environment
rm(gdp_raw)
## 2.5 Number of asylum seekers
# Keep necessary columns
refugee <- refugee_raw[, c(2, 4)]
# Rename columns
names(refugee) <- c("ID", "n.refugees")
# Remove raw data from environment
rm(refugee_raw)
## 2.6 District public debt
# Keep necessary columns
debt <- debt_raw[, c(2, 4)]
# Rename columns
names(debt) <- c("ID", "public.debt")
View(debt)
View(debt)
debt$public.debt <- debt$public.debt/1000
rm(debt_raw)
View(debt)
type <- size_raw[, c(2, 3)]
# Create type column
type$district.type <- 0
type$district.type[grep('Kreisfreie Stadt', type$district.name)] <- 1
# Rename column
names(type) <- c("ID", "district.name", "district.type")
# Remove used column
type$district.name <- NULL
# Remove raw data from the environment
rm(size_raw)
View(type)
--------------------------------------#
# Merge the data into the final data frame
Data <- merge(data.election, size, "ID")
Data <- merge(Data, edu, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, refugee, "ID")
Data <- merge(Data, debt, "ID")
Data <- merge(Data, type, "ID")
# Remove used data frames
rm(data.election)
rm(size)
rm(edu)
rm(unemp)
rm(gdp)
rm(refugee)
rm(debt)
rm(type)
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Collaborative Research Project
# Creating the Dataset
# Johannes Schulz-Knappe
# Update 16 May 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
## 1.1 Clear the environment
rm(list = ls())
## 1.2 Load packages for dataset creation
# Create vector of used packages
packages <- c('repmis', 'rvest', 'plyr', 'rio', 'xlsx')
# Install packages that are not already installed
for (p in packages) {
if (p %in% installed.packages()[,1]) require(p, character.only=TRUE)
else {
install.packages(p)
require(p, character.only=TRUE)
}
}
rm(p)
# Load packages
loaded <- lapply(packages, require, character.only = TRUE)
rm(loaded)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
## 1.4 Create bibTeX file for the used packages
LoadandCite(packages, file = 'Packages1.bib')
rm(packages)
#-----------------------------------------#
# 2. Run gathering and cleaning R files   #
#-----------------------------------------#
# Dynamically run R files in this order
## 2.1 Electoral data gathering
source("data_gathering/election_data_gathering.R")
## 2.2 Structural data gathering
source("data_gathering/structural_data_gathering.R")
## 2.3 Electoral data cleaning
source("data_cleaning/election_data_cleaning.R")
## 2.4 Structural data cleaning
source("data_cleaning/structural_data_cleaning.R")
View(size)
Data <- merge(data.election, size, "ID")
View(Data)
Data <- merge(Data, edu, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, refugee, "ID")
Data <- merge(Data, debt, "ID")
Data <- merge(Data, type, "ID")
rm(data.election)
rm(size)
rm(edu)
rm(unemp)
rm(gdp)
rm(refugee)
rm(debt)
rm(type)
View(Data)
Data[, c(13, 14, 16, 18)] <- round(as.matrix(Data[, c(13, 14, 16, 18)]), digits=2)
save(Data, file = "Data_new.Rda")
