govqual <- read.table('http://www.qogdata.pol.gu.se/data/qog_std_ts_jan16.csv')
govqual <- import('http://www.qogdata.pol.gu.se/data/qog_std_ts_jan16.csv')
library(import)
library(rio)
install.packages(rio)
install.packages('rio')
library(rio)
govqual <- import('http://www.qogdata.pol.gu.se/data/qog_std_ts_jan16.csv')
install.packages("repmis")
load <- c("dplyr", "magrittr", "readstata13", "ggplot2", "reshape",
"plyr", "repmis")
loaded <- lapply(load, require, character.only = T)
rm(list = ls()) #just to clear all
install.packages("dplyr")
install.packages("magrittr")
install.packages("readstata13")
install.packages("ggplot2")
install.packages("reshape")
install.packages("plyr")
install.packages("repmis")
load <- c("dplyr", "magrittr", "readstata13", "ggplot2", "reshape",
"plyr", "repmis")
loaded <- lapply(load, require, character.only = T)
rm(load, loaded)
data(USArrests) # to load the data
names(USArrests) # to see names of variables
dim(USArrests) # to see how big the data frame, for instance, it has 50 rows, 4 variables
arrange(USArrests, murder) # to arrage data to see at a glance which state has highest murder rate
arrange(USArrests, Murder) # to arrage data to see at a glance which state has highest murder rate
attributes(USArrests)
attributes(USArrests)$row.names
attributes(USArrests)
USArrests <- rename(USArrests, c(Assault  = "assault",
Murder   = "murder",
UrbanPop = "urbanpop",
Rape     = "rape"))
USArrests$states <- row.names(USArrests)  # creating "states"
USArrests$states <- row.names(USArrests)  # creating "states" variable
USArrests <- USArrests[, c(5,1:4)]
View(USArrests)
for (i in 1:length(names(USArrests))) {
USArrests[, i] %>%
mean() %>%
round(digits = 3) %>%
paste(names(USArrests)[i], ., '\n') %>%
cat()
}
View(i)
i
for (i in 1:length(names(USArrests))) {
USArrests[, i] %>%
median() %>%
round(digits = 3) %>%
paste(names(USArrests)[i], ., '\n') %>%
cat()
}
mean(USArrests$murder, na.rm = TRUE)
mean(USArrests$assault, na.rm = TRUE)
mean(USArrests$urbanpop, na.rm = TRUE)
mean(USArrests$rape, na.rm = TRUE)
median(USArrests$murder, na.rm = TRUE)
median(USArrests$assault, na.rm = TRUE)
median(USArrests$urbanpop, na.rm = TRUE)
median(USArrests$rape, na.rm = TRUE)
range(USArrests$murder)
range(USArrests$assault)
range(USArrests$urbanpop)
range(USArrests$rape)
summary(USArrests$murder, assault, urbanpop, rape)
summary(USArrests)
summary(USArrests)
ggplot(USArrests) +
geom_bar(aes(y = murder, x = reorder(states, -murder)),
stat = "identity") +
ylab("Murder Rate per 100,000") +
xlab("State") +
ggtitle("Murder Rate in the United States in 1973") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90))
ggplot(USArrests) +
geom_bar(aes(y = rape, x = reorder(states, -rape)),
stat = "identity") +
ylab("Rape arrests (per 100,000)") +
xlab("States") +
ggtitle("Rape rate in the United States in 1973") +
theme_bw() +
coord_flip()
ggplot(USArrests) +
geom_bar(aes(y = rape, x = reorder(states, -rape)),
stat = "identity") +
ylab("Rape arrests (per 100,000)") +
xlab("States") +
ggtitle("Rape rate in the United States in 1973") +
theme_bw() +
coord_flip()
ggplot(USArrests) +
geom_histogram(aes(x = urbanpop),
colour = "black",
fill = "transparent",
binwidth = 2) +
ylab("Frequency") +
xlab("Population in % living in urban areas") +
theme_bw()
states <- row.names(USArrests)
barplot(USArrests$murder,
names.arg = states,
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = reorder(states, -murder),
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = reorder(states, -Murder),
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = states,
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000')
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)',
ylab = 'Number of States'
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)',
ylab = 'Number of States')
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)')
library(dplyr)
library(rvest)
install.packages('rvest')
library(rvest)
URL <- http://www.bbc.com/sport/winter-olympics/2014/medals/countries
URL <- 'http://www.bbc.com/sport/winter-olympics/2014/medals/countries'
# Get and parse expenses_table from the webpage
MedalTable <- URL %>% read_html() %>%
html_nodes('#medals-table') %>%
html_table() %>%
as.data.frame
View(MedalTable)
# Get and parse expenses_table from the webpage
MedalsTable <- URL %>% read_html() %>%
html_nodes('medals-table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('medals-table__table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals-table__table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
rm(list = ls())
library(dplyr)
library(rvest)
URL <- 'http://www.bbc.com/sport/winter-olympics/2014/medals/countries'
MedalsTable <- URL %>% read_html() %>%
html_nodes('#orb-nav-links') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals_table') %>%
html_table() %>%
as.data.frame
html_nodes('#medals__table') %>%
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals__table') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals_table__table') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#orb-nav-links') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals-table__total--silver') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#table') %>%
html_table() %>%
as.data.frame
# Get and parse expenses_table from the webpage
MedalsTable <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
head(MedalsTable)
drop(NA.$MedalsTable)
drop(MedalsTable$NA.)
head(MedalsTable)
MedalsTable$NA. <- NULL
head(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table() %>%
as.data.frame
head(MedalsTable)
View(MedalsTable)
MedalsTable$NA. <- NULL
View(MedalsTable)
TotalMedals <- arrange(MedalsTable, desc(Total))
head(TotalMedals)
tables <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table()
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment02',
'C:/Users/User/Documents/GitHub/Assignment02')
toBibtex(citation())
# Saxony Anhalt 2016
sa16 <- read.csv('http://www.statistik.sachsen-anhalt.de/wahlen/lt16/erg/csv/lt16dat2.csv',
sep = ';')
View(sa16)
rp16 <- read.csv('Data_Files/wahlnachtanalyse-lw2016_page_65.csv', header = FALSE, sep = ';')
trees <- c('Jomon Sugi', 'Huon Pine')
View(trees)
str_split_fixed(trees, pattern = ' ', n = 2)
library(stringr)
str_split_fixed(trees, pattern = ' ', n = 2)
View(trees)
str_split_fixed(trees, pattern = ' ', n = 2)
trees2 <- data.frame[str_split_fixed(trees, pattern = ' ', n = 2)]
trees2 <- str_split_fixed(trees, pattern = ' ', n = 2)
View(trees2)
trees <- c('1 Sugi', '2 Pine')
View(trees)
trees <- c('1 Sugi', '2 Pine')
View(trees)
trees2 <- str_split_fixed(trees, pattern = ' ', n = 2)
View(trees2)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
library(xlsx)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
library(xlsx)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
library(repmis)
library(rio)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
View(rp16)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx', format = xlsx,
2, cache = TRUE)
2, cache = TRUE)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx', format = 'xlsx',
2, cache = TRUE)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx', format = 'xlsx',
2)
View(rp16)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx', format = 'xlsx',
sheetIndex = 2)
View(Data)
View(Data.Rda)
load(Data.Rda)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
set_valid_wd(possible_dir) # Set to first valid directory in the possible_dir vector
rm(possible_dir) # remove possible_dir vector
load("Data.Rda") # Load data file
rm(list = ls())
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
``` {r initialisation, echo = F, message = F, warning = F}
#options(repos=c(CRAN="http://mirrors.softliste.de/cran/"))
rm(list = ls())
load <- c("repmis", "magrittr", "scales", "betareg", "dplyr", "xtable", "texreg",
"stargazer", "readxl", "ggplot2", "grid",
"captioner", "foreign", "rms", "Zelig",
"knitr", "GGally", "gridExtra",
"zoo", "rugarch", "psych")
loaded <- lapply(load, function(x) {
if(!require(x, character.only = T)) {
install.packages(x)
require(x, character.only = T)
}
})
rm(load, loaded)
figcap <- captioner(prefix = "Figure",
auto_space = TRUE, levels = 1, type = NULL)
tablecap <- captioner(prefix = "Table",
auto_space = TRUE, levels = 1, type = NULL)
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
set_valid_wd(possible_dir) # Set to first valid directory in the possible_dir vector
rm(possible_dir) # remove possible_dir vector
load("Data_new.Rda") # Load data file
View(Data)
View(Data)
View(Data)
Data$vote.AfD.prcnt <- Data$vote.AfD/100
reord <- Data[c(0:3, 20, 5:19, 4)] #reordering variable to replace vote.AfD.prcnt variable in place of vote.AfD
View(reord)
Data <- reord
```{r sumstat, echo=F, warning=F, message=F, error=F, results='asis'}
summary_labels <- c('Vote share of AfD in 2016', 'Vote turnout in 2011',
'Vote share of CDU in 2011', 'Vote share of Greens in 2011',
'Vote share of SPD in 2011', 'Vote share of FDP in 2011',
'Vote share of Linke in 2011', 'High school ratio',
'No degree ratio', 'GDP per capita / 1000',
'Unemployment rate', 'Number of refugees')
stargazer(Data[4:16],
covariate.labels = summary_labels,
font.size = 'tiny',
title= 'Summary statistics of the covariates',
type="latex", header = FALSE)
```{r corr, echo=F, warning=F, message=F, error=F, results='asis'}
correlation.matrix <- cor(Data[, c("vote.AfD","lag.CDU",
"lag.SPD","GDP.capita",
"unempl.rate",
"abitur.ratio")])
stargazer(correlation.matrix,
title= 'Correlation matrix of some variables',
font.size = 'tiny',
digits = 2,
type="latex",
header = FALSE,
no.space = FALSE)
``` {r regout, echo = F, message = F, results = "asis", error=F}
reg1 <- lm(vote.AfD ~ GDP.capita + unempl.rate + n.refugees, data = Data)
reg2 <- lm(vote.AfD ~ GDP.capita + unempl.rate + n.refugees + lag.CDU +
lag.SPD + lag.turnout, data = Data)
reg3 <- lm(vote.AfD ~ GDP.capita + unempl.rate + n.refugees +
abitur.ratio + nodegree.ratio, data = Data)
reg4 <- lm(vote.AfD ~ GDP.capita + unempl.rate + n.refugees
+ lag.CDU + lag.SPD + lag.turnout + abitur.ratio +
nodegree.ratio, data = Data)
reg5 <- lm(vote.AfD ~ GDP.capita + unempl.rate + n.refugees
+ lag.CDU + lag.SPD + lag.turnout + abitur.ratio +
nodegree.ratio + state, data = Data)
var_labels <- c('GDP per capita / 1000', 'Unemployment rate', 'Number of refugees',
'Vote share of CDU in 2011 election',
'Vote share of SPD in 2011 election',
'Voter turnout in 2011 election',
'Abitur ratio', 'No degree ratio', 'state')
stargazer::stargazer(reg1, reg2, reg3, reg4, reg5,
omit = 'as.factor*',
omit.stat = c('f', 'ser'), # to nicely fits on the page
out.header = F,
title = 'Determinants of electoral success for the Alternative for Germany',
dep.var.labels = 'Vote share of AfD',
covariate.labels = var_labels,
label = 'AfD_voteshare',
add.lines = list(c('District FE', rep('NO', 5))),
font.size = 'tiny', # make the font tiny
float = F, df = F, # add float and df to F
type="latex", header = F,
no.space = T,
digits = 2) # add no.space=TRUE to remove space in betwen line.
View(Data)
