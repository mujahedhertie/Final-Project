-.02494986/.01802799
.02226671/.01464402
-.00268315/.02367888
-.01841561/.06885857
.02789547/.01696463
.02226671/.01691368
.02226671/ .01497513
.09141282/.03717104
.10582395/.03999136
.02772757/ .01811312
.02933798/ .01896894
.02933798/ .01896894
-.01837071/.01356265
.00448299/.00949094
.022/.014
-.00268315/.02367888
.0092613/.0516263
.02772757 /.01882672
.03/.01
0.3/.02
.03/.02
.03/.01
.028/.018
.01/ -.00
.02977368 / .01862503
.02/ .01
.02/.01
.022/.014
.02/.01
rm(list = ls())
load <- c("dplyr", "magrittr", "readstata13", "ggplot2")
loaded <- lapply(load, require, character.only = T)
rm(load, loaded)
folder.path <- "C:/Users/User/Desktop/DESKTOP/Forth Semester/Longitudinal Data Analysis/final_project/"
coef.data <- read.csv(paste0(folder.path, "coefplot.csv"),
header = F)
colnames(coef.data) <- c("var", "est", "se")
View(coef.data)
png(paste0(folder.path, "coefplot.png"),
width = 800, height = 700,
res = 200, type = "cairo")
ggplot(coef.data, aes(est, var)) +
geom_errorbarh(aes(xmin = est - 1.96*se, xmax = est + 1.96*se),
height = 0.2, colour = "grey48") +
geom_point(size = 0.8) +
geom_vline(xintercept = 0, colour = "grey48",
linetype = "dotted") +
xlab("Logit Estimates") +
ggtitle("Party support") +
theme_bw() +
theme(axis.title.y = element_blank())
dev.off()
png(paste0(folder.path, "coefplot.png"),
width = 1000, height = 800,
res = 200, type = "cairo")
ggplot(coef.data, aes(est, var)) +
geom_errorbarh(aes(xmin = est - 1.96*se, xmax = est + 1.96*se),
height = 0.2, colour = "grey48") +
geom_point(size = 0.8) +
geom_vline(xintercept = 0, colour = "grey48",
linetype = "dotted") +
xlab("Logit Estimates") +
ggtitle("Party support") +
theme_bw() +
theme(axis.title.y = element_blank())
dev.off()
png(paste0(folder.path, "coefplot.png"),
width = 1000, height = 900,
res = 200, type = "cairo")
ggplot(coef.data, aes(est, var)) +
geom_errorbarh(aes(xmin = est - 1.96*se, xmax = est + 1.96*se),
height = 0.2, colour = "grey48") +
geom_point(size = 0.8) +
geom_vline(xintercept = 0, colour = "grey48",
linetype = "dotted") +
xlab("Logit Estimates") +
ggtitle("Party support") +
theme_bw() +
theme(axis.title.y = element_blank())
dev.off()
png(paste0(folder.path, "coefplot.png"),
width = 1000, height = 1200,
res = 200, type = "cairo")
ggplot(coef.data, aes(est, var)) +
geom_errorbarh(aes(xmin = est - 1.96*se, xmax = est + 1.96*se),
height = 0.2, colour = "grey48") +
geom_point(size = 0.8) +
geom_vline(xintercept = 0, colour = "grey48",
linetype = "dotted") +
xlab("Logit Estimates") +
ggtitle("Party support") +
theme_bw() +
theme(axis.title.y = element_blank())
dev.off()
png(paste0(folder.path, "coefplot.png"),
width = 1000, height = 1200,
res = 200, type = "cairo")
ggplot(coef.data, aes(est, var)) +
geom_errorbarh(aes(xmin = est - 1.96*se, xmax = est + 1.96*se),
height = 0.2, colour = "grey48") +
geom_point(size = 0.8) +
geom_vline(xintercept = 0, colour = "grey48",
linetype = "dotted") +
xlab("Random effect logit estimates") +
ggtitle("Party support") +
theme_bw() +
theme(axis.title.y = element_blank())
dev.off()
png(paste0(folder.path, "coefplot.png"),
width = 800, height = 1000,
res = 200, type = "cairo")
ggplot(coef.data, aes(est, var)) +
geom_errorbarh(aes(xmin = est - 1.96*se, xmax = est + 1.96*se),
height = 0.2, colour = "grey48") +
geom_point(size = 0.8) +
geom_vline(xintercept = 0, colour = "grey48",
linetype = "dotted") +
xlab("Random effect logit estimates") +
ggtitle("Party support") +
theme_bw() +
theme(axis.title.y = element_blank())
dev.off()
png(paste0(folder.path, "coefplot.png"),
width = 1000, height = 1200,
res = 200, type = "cairo")
ggplot(coef.data, aes(est, var)) +
geom_errorbarh(aes(xmin = est - 1.96*se, xmax = est + 1.96*se),
height = 0.2, colour = "grey48") +
geom_point(size = 0.8) +
geom_vline(xintercept = 0, colour = "grey48",
linetype = "dotted") +
xlab("Random effect logit estimates") +
ggtitle("Party support") +
theme_bw() +
theme(axis.title.y = element_blank())
dev.off()
png(paste0(folder.path, "coefplot.png"),
width = 1000, height = 1200,
res = 200, type = "cairo")
ggplot(coef.data, aes(est, var)) +
geom_errorbarh(aes(xmin = est - 1.96*se, xmax = est + 1.96*se),
height = 0.2, colour = "blue") +
geom_point(size = 0.8) +
geom_vline(xintercept = 0, colour = "grey48",
linetype = "dotted") +
xlab("Random effect logit estimates") +
ggtitle("Party support") +
theme_bw() +
theme(axis.title.y = element_blank())
dev.off()
png(paste0(folder.path, "coefplot.png"),
width = 1000, height = 1200,
res = 200, type = "cairo")
ggplot(coef.data, aes(est, var)) +
geom_errorbarh(aes(xmin = est - 1.96*se, xmax = est + 1.96*se),
height = 0.2, colour = "blue") +
geom_point(size = 0.8) +
geom_vline(xintercept = 0, colour = "blue",
linetype = "dotted") +
xlab("Random effect logit estimates") +
ggtitle("Party support") +
theme_bw() +
theme(axis.title.y = element_blank())
dev.off()
data(mtcars)
View(mtcars)
m_cyl <- lm(mpg ~ wt * cyl, data = mtcars)
summary(m_cyl)
install.packages(""interplot"")
install.packages("interplot")
library(interplot)
m_cyl <- lm(mpg ~ wt * cyl, data = mtcars)
interplot(m = m_cyl, var1 = "cyl", var2 = "wt")
m_cyl <- lm(mpg ~ wt * cyl, data = mtcars)
vcov(m_cyl)
describe(m_cyl)
describe(mtcars)
describe(mtcars)
m_cyl <- lm(mpg ~ wt * cyl, data = mtcars)
vcov(m_cyl)
describe(mtcars)
m_cyl <- lm(mpg ~ wt * cyl, data = mtcars)
summary(m_cyl)
vcov(m_cyl)
describe(mtcars)
install.packages("psych")
library(psych)
describe(mtcars)
library(ggplot2 )
library(ggplot2)
dat=mtcars
View(dat)
dat$am=as.factor(dat$am)
dat$vs=as.factor(dat$vs)
m_cyl <- lm(mpg ~ wt * cyl, data = mtcars)
summary(m_cyl)
vcov(m_cyl)
describe(mtcars)
View(dat)
dat2 = describeBy(dat$mpg,list(dat$am,dat$vs), mat=TRUE,digits=2)
View(dat2)
names(dat2)[names(dat2) == 'group1'] = 'Transmission'
names(dat2)[names(dat2) == 'group2'] = 'VS'
levels(dat2$Transmission)[levels(dat2$Transmission)=='0'] = 'Automatic'
levels(dat2$Transmission)[levels(dat2$Transmission)=='1'] = 'Manual
View(dat2)
View(dat2)
levels(dat2$Transmission)[levels(dat2$Transmission)=='1'] = 'Manual'
View(dat2)
dat2 = describeBy(dat$mpg,list(dat$am,dat$vs), mat=TRUE,digits=2)
names(dat2)[names(dat2) == 'group1'] = 'Transmission'
names(dat2)[names(dat2) == 'group2'] = 'VS'
levels(dat2$Transmission)[levels(dat2$Transmission)=='0'] = 'Automatic'
levels(dat2$Transmission)[levels(dat2$Transmission)=='1'] = 'Manual'
View(dat2)
dat2$se = dat2$sd/sqrt(dat2$n)
View(dat2)
limits = aes(ymax = mean + (1.96*se), ymin=mean - (1.96*se))
dodge = position_dodge(width=0.9)
apatheme=theme_bw()+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
panel.border=element_blank(),
axis.line=element_line(),
text=element_text(family='Times'))
p=ggplot(dat2, aes(x = Transmission, y = mean, fill = VS))+
geom_bar(stat='identity', position=dodge)+
geom_errorbar(limits, position=dodge, width=0.25)+
apatheme+
ylab('Mean MPG')+
scale_fill_grey()
p
```{r interaction, echo=F, warning=F, message=F, error=F}
Data$state=as.factor(Data$state)
rega1 <- lm(vote.AfD ~ state*unempl.rate, data = Data)
summary(rega1)
Data$predicted=predict(rega1)
apatheme=theme_bw()+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
panel.border=element_blank(),
axis.line=element_line(),
text=element_text(family='Times'))
p=ggplot(Data, aes(x=unempl.rate, y=vote.AfD.prcnt, shape=state))+
geom_point()+
scale_shape_manual(values=c(1,16), name='State', labels=c('Saxony Anhalt','Badenwutemberg', 'Berlin'))+
geom_line(aes(x = unempl.rate, y = predicted, linetype=state)) +
scale_linetype_discrete(name='State', labels=c('Saxony Anhalt','Badenwutemberg', 'Berlin'))+
labs(x = 'Unemployment rate', y = 'Vote share of AfD')+
apatheme
p
```{r interaction, echo=F, warning=F, message=F, error=F}
Data$state=as.factor(Data$state)
rega1 <- lm(vote.AfD.prcnt ~ state*unempl.rate, data = Data)
summary(rega1)
Data$predicted=predict(rega1)
apatheme=theme_bw()+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
panel.border=element_blank(),
axis.line=element_line(),
text=element_text(family='Times'))
p=ggplot(Data, aes(x=unempl.rate, y=vote.AfD.prcnt, shape=state))+
geom_point()+
scale_shape_manual(values=c(1,16), name='State', labels=c('Saxony Anhalt','Badenwutemberg', 'Berlin'))+
geom_line(aes(x = unempl.rate, y = predicted, linetype=state)) +
scale_linetype_discrete(name='State', labels=c('Saxony Anhalt','Badenwutemberg', 'Berlin'))+
labs(x = 'Unemployment rate', y = 'Vote share of AfD')+
apatheme
p
```
View(mtcars)
```{r interaction, echo=F, warning=F, message=F, error=F}
#rega1 <- lm(vote.AfD.prcnt ~ state*unempl.rate, data = Data)
Data$state=as.factor(Data$state)
rega1 <- lm(vote.AfD.prcnt ~ GDP.capita + state*unempl.rate + n.refugees
+ lag.CDU + lag.SPD + lag.turnout + abitur.ratio +
nodegree.ratio, data = Data)
summary(rega1)
Data$predicted=predict(rega1)
apatheme=theme_bw()+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
panel.border=element_blank(),
axis.line=element_line(),
text=element_text(family='Times'))
p=ggplot(Data, aes(x=unempl.rate, y=vote.AfD.prcnt, shape=state))+
geom_point()+
scale_shape_manual(values=c(1,6,9), name='Districts', labels=c('Rhineland-Palatinate','Baden-WÃ¼rttemberg', 'Saxony-Anhalt'))+
geom_line(aes(x = unempl.rate, y = predicted, linetype=state)) +
scale_linetype_discrete(name='Districts', labels=c('Rhineland-Palatinate','Baden-WÃ¼rttemberg', 'Saxony-Anhalt'))+
labs(x = 'Unemployment rate', y = 'Vote share of AfD')+
apatheme
p
ggsave('scatter1.png', width=6, height=6, unit='in', dpi=300)
```
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Collaborative Research Project
# Creating the Dataset
# Johannes Schulz-Knappe
# Update 01 May 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
## 1.1 Clear the environment
rm(list = ls())
## 1.2 Load packages for dataset creation
# Create vector of used packages
packages <- c('repmis', 'rvest', 'plyr', 'rio', 'xlsx')
# Install packages that are not already installed
for (p in packages) {
if (p %in% installed.packages()[,1]) require(p, character.only=TRUE)
else {
install.packages(p)
require(p, character.only=TRUE)
}
}
rm(p)
# Load packages
loaded <- lapply(packages, require, character.only = TRUE)
rm(loaded)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
## 1.4 Create bibTeX file for the used packages
LoadandCite(packages, file = 'Packages1.bib')
rm(packages)
#-----------------------------------------#
# 2. Run gathering and cleaning R files   #
#-----------------------------------------#
# Dynamically run R files in this order
## 2.1 Electoral data gathering
source("data_gathering/election_data_gathering.R")
## 2.2 Structural data gathering
source("data_gathering/structural_data_gathering.R")
## 2.3 Electoral data cleaning
source("data_cleaning/election_data_cleaning.R")
## 2.4 Structural data cleaning
source("data_cleaning/structural_data_cleaning.R")
#-----------------------------------------#
# 3. Merge the data                       #
#-----------------------------------------#
# Merge the data into the final data frame
Data <- merge(data.election, size, "ID")
Data <- merge(Data, edu, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, refugee, "ID")
Data <- merge(Data, debt, "ID")
# Remove used data frames
rm(data.election)
rm(size)
rm(edu)
rm(unemp)
rm(gdp)
rm(refugee)
rm(debt)
# Save Data as file in repository
save(Data, file = "Data_new.Rda")
save(Data, file = "Data_new.Rda")
save(Data, file = "Data_new.Rda")
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Collaborative Research Project
# Creating the Dataset
# Johannes Schulz-Knappe
# Update 01 May 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
## 1.1 Clear the environment
rm(list = ls())
## 1.2 Load packages for dataset creation
# Create vector of used packages
packages <- c('repmis', 'rvest', 'plyr', 'rio', 'xlsx')
# Install packages that are not already installed
for (p in packages) {
if (p %in% installed.packages()[,1]) require(p, character.only=TRUE)
else {
install.packages(p)
require(p, character.only=TRUE)
}
}
rm(p)
# Load packages
loaded <- lapply(packages, require, character.only = TRUE)
rm(loaded)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
## 1.4 Create bibTeX file for the used packages
LoadandCite(packages, file = 'Packages1.bib')
rm(packages)
#-----------------------------------------#
# 2. Run gathering and cleaning R files   #
#-----------------------------------------#
# Dynamically run R files in this order
## 2.1 Electoral data gathering
source("data_gathering/election_data_gathering.R")
## 2.2 Structural data gathering
source("data_gathering/structural_data_gathering.R")
## 2.3 Electoral data cleaning
source("data_cleaning/election_data_cleaning.R")
## 2.4 Structural data cleaning
source("data_cleaning/structural_data_cleaning.R")
#-----------------------------------------#
# 3. Merge the data                       #
#-----------------------------------------#
# Merge the data into the final data frame
Data <- merge(data.election, size, "ID")
Data <- merge(Data, edu, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, refugee, "ID")
Data <- merge(Data, debt, "ID")
# Remove used data frames
rm(data.election)
rm(size)
rm(edu)
rm(unemp)
rm(gdp)
rm(refugee)
rm(debt)
# Save Data as file in repository
save(Data, file = "Data_new.Rda")
rm(list = ls())
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Collaborative Research Project
# Creating the Dataset
# Johannes Schulz-Knappe
# Update 01 May 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
## 1.1 Clear the environment
rm(list = ls())
## 1.2 Load packages for dataset creation
# Create vector of used packages
packages <- c('repmis', 'rvest', 'plyr', 'rio', 'xlsx')
# Install packages that are not already installed
for (p in packages) {
if (p %in% installed.packages()[,1]) require(p, character.only=TRUE)
else {
install.packages(p)
require(p, character.only=TRUE)
}
}
rm(p)
# Load packages
loaded <- lapply(packages, require, character.only = TRUE)
rm(loaded)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
## 1.4 Create bibTeX file for the used packages
LoadandCite(packages, file = 'Packages1.bib')
rm(packages)
#-----------------------------------------#
# 2. Run gathering and cleaning R files   #
#-----------------------------------------#
# Dynamically run R files in this order
## 2.1 Electoral data gathering
source("data_gathering/election_data_gathering.R")
## 2.2 Structural data gathering
source("data_gathering/structural_data_gathering.R")
## 2.3 Electoral data cleaning
source("data_cleaning/election_data_cleaning.R")
## 2.4 Structural data cleaning
source("data_cleaning/structural_data_cleaning.R")
#-----------------------------------------#
# 3. Merge the data                       #
#-----------------------------------------#
# Merge the data into the final data frame
Data <- merge(data.election, size, "ID")
Data <- merge(Data, edu, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, refugee, "ID")
Data <- merge(Data, debt, "ID")
# Remove used data frames
rm(data.election)
rm(size)
rm(edu)
rm(unemp)
rm(gdp)
rm(refugee)
rm(debt)
# Save Data as file in repository
save(Data, file = "Data_new.Rda")
