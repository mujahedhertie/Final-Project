govqual <- read.table('http://www.qogdata.pol.gu.se/data/qog_std_ts_jan16.csv')
govqual <- import('http://www.qogdata.pol.gu.se/data/qog_std_ts_jan16.csv')
library(import)
library(rio)
install.packages(rio)
install.packages('rio')
library(rio)
govqual <- import('http://www.qogdata.pol.gu.se/data/qog_std_ts_jan16.csv')
install.packages("repmis")
load <- c("dplyr", "magrittr", "readstata13", "ggplot2", "reshape",
"plyr", "repmis")
loaded <- lapply(load, require, character.only = T)
rm(list = ls()) #just to clear all
install.packages("dplyr")
install.packages("magrittr")
install.packages("readstata13")
install.packages("ggplot2")
install.packages("reshape")
install.packages("plyr")
install.packages("repmis")
load <- c("dplyr", "magrittr", "readstata13", "ggplot2", "reshape",
"plyr", "repmis")
loaded <- lapply(load, require, character.only = T)
rm(load, loaded)
data(USArrests) # to load the data
names(USArrests) # to see names of variables
dim(USArrests) # to see how big the data frame, for instance, it has 50 rows, 4 variables
arrange(USArrests, murder) # to arrage data to see at a glance which state has highest murder rate
arrange(USArrests, Murder) # to arrage data to see at a glance which state has highest murder rate
attributes(USArrests)
attributes(USArrests)$row.names
attributes(USArrests)
USArrests <- rename(USArrests, c(Assault  = "assault",
Murder   = "murder",
UrbanPop = "urbanpop",
Rape     = "rape"))
USArrests$states <- row.names(USArrests)  # creating "states"
USArrests$states <- row.names(USArrests)  # creating "states" variable
USArrests <- USArrests[, c(5,1:4)]
View(USArrests)
for (i in 1:length(names(USArrests))) {
USArrests[, i] %>%
mean() %>%
round(digits = 3) %>%
paste(names(USArrests)[i], ., '\n') %>%
cat()
}
View(i)
i
for (i in 1:length(names(USArrests))) {
USArrests[, i] %>%
median() %>%
round(digits = 3) %>%
paste(names(USArrests)[i], ., '\n') %>%
cat()
}
mean(USArrests$murder, na.rm = TRUE)
mean(USArrests$assault, na.rm = TRUE)
mean(USArrests$urbanpop, na.rm = TRUE)
mean(USArrests$rape, na.rm = TRUE)
median(USArrests$murder, na.rm = TRUE)
median(USArrests$assault, na.rm = TRUE)
median(USArrests$urbanpop, na.rm = TRUE)
median(USArrests$rape, na.rm = TRUE)
range(USArrests$murder)
range(USArrests$assault)
range(USArrests$urbanpop)
range(USArrests$rape)
summary(USArrests$murder, assault, urbanpop, rape)
summary(USArrests)
summary(USArrests)
ggplot(USArrests) +
geom_bar(aes(y = murder, x = reorder(states, -murder)),
stat = "identity") +
ylab("Murder Rate per 100,000") +
xlab("State") +
ggtitle("Murder Rate in the United States in 1973") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90))
ggplot(USArrests) +
geom_bar(aes(y = rape, x = reorder(states, -rape)),
stat = "identity") +
ylab("Rape arrests (per 100,000)") +
xlab("States") +
ggtitle("Rape rate in the United States in 1973") +
theme_bw() +
coord_flip()
ggplot(USArrests) +
geom_bar(aes(y = rape, x = reorder(states, -rape)),
stat = "identity") +
ylab("Rape arrests (per 100,000)") +
xlab("States") +
ggtitle("Rape rate in the United States in 1973") +
theme_bw() +
coord_flip()
ggplot(USArrests) +
geom_histogram(aes(x = urbanpop),
colour = "black",
fill = "transparent",
binwidth = 2) +
ylab("Frequency") +
xlab("Population in % living in urban areas") +
theme_bw()
states <- row.names(USArrests)
barplot(USArrests$murder,
names.arg = states,
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = reorder(states, -murder),
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = reorder(states, -Murder),
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = states,
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000')
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)',
ylab = 'Number of States'
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)',
ylab = 'Number of States')
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)')
library(dplyr)
library(rvest)
install.packages('rvest')
library(rvest)
URL <- http://www.bbc.com/sport/winter-olympics/2014/medals/countries
URL <- 'http://www.bbc.com/sport/winter-olympics/2014/medals/countries'
# Get and parse expenses_table from the webpage
MedalTable <- URL %>% read_html() %>%
html_nodes('#medals-table') %>%
html_table() %>%
as.data.frame
View(MedalTable)
# Get and parse expenses_table from the webpage
MedalsTable <- URL %>% read_html() %>%
html_nodes('medals-table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('medals-table__table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals-table__table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
rm(list = ls())
library(dplyr)
library(rvest)
URL <- 'http://www.bbc.com/sport/winter-olympics/2014/medals/countries'
MedalsTable <- URL %>% read_html() %>%
html_nodes('#orb-nav-links') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals_table') %>%
html_table() %>%
as.data.frame
html_nodes('#medals__table') %>%
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals__table') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals_table__table') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#orb-nav-links') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals-table__total--silver') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#table') %>%
html_table() %>%
as.data.frame
# Get and parse expenses_table from the webpage
MedalsTable <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
head(MedalsTable)
drop(NA.$MedalsTable)
drop(MedalsTable$NA.)
head(MedalsTable)
MedalsTable$NA. <- NULL
head(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table() %>%
as.data.frame
head(MedalsTable)
View(MedalsTable)
MedalsTable$NA. <- NULL
View(MedalsTable)
TotalMedals <- arrange(MedalsTable, desc(Total))
head(TotalMedals)
tables <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table()
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment02',
'C:/Users/User/Documents/GitHub/Assignment02')
toBibtex(citation())
# Saxony Anhalt 2016
sa16 <- read.csv('http://www.statistik.sachsen-anhalt.de/wahlen/lt16/erg/csv/lt16dat2.csv',
sep = ';')
View(sa16)
rp16 <- read.csv('Data_Files/wahlnachtanalyse-lw2016_page_65.csv', header = FALSE, sep = ';')
trees <- c('Jomon Sugi', 'Huon Pine')
View(trees)
str_split_fixed(trees, pattern = ' ', n = 2)
library(stringr)
str_split_fixed(trees, pattern = ' ', n = 2)
View(trees)
str_split_fixed(trees, pattern = ' ', n = 2)
trees2 <- data.frame[str_split_fixed(trees, pattern = ' ', n = 2)]
trees2 <- str_split_fixed(trees, pattern = ' ', n = 2)
View(trees2)
trees <- c('1 Sugi', '2 Pine')
View(trees)
trees <- c('1 Sugi', '2 Pine')
View(trees)
trees2 <- str_split_fixed(trees, pattern = ' ', n = 2)
View(trees2)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
library(xlsx)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
library(xlsx)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
library(repmis)
library(rio)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
View(rp16)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx', format = xlsx,
2, cache = TRUE)
2, cache = TRUE)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx', format = 'xlsx',
2, cache = TRUE)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx', format = 'xlsx',
2)
View(rp16)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx', format = 'xlsx',
sheetIndex = 2)
View(Data)
View(Data.Rda)
load(Data.Rda)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
set_valid_wd(possible_dir) # Set to first valid directory in the possible_dir vector
rm(possible_dir) # remove possible_dir vector
load("Data.Rda") # Load data file
rm(list = ls())
load("C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project/Data_new.Rda")
View(Data)
View(Data)
rm(list = ls())
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Collaborative Research Project
# Creating the Dataset
# Johannes Schulz-Knappe
# Update 16 May 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
## 1.1 Clear the environment
rm(list = ls())
## 1.2 Load packages for dataset creation
# Create vector of used packages
packages <- c('repmis', 'rvest', 'plyr', 'rio', 'xlsx')
# Install packages that are not already installed
for (p in packages) {
if (p %in% installed.packages()[,1]) require(p, character.only=TRUE)
else {
install.packages(p)
require(p, character.only=TRUE)
}
}
rm(p)
# Load packages
loaded <- lapply(packages, require, character.only = TRUE)
rm(loaded)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
## 1.4 Create bibTeX file for the used packages
LoadandCite(packages, file = 'Packages1.bib')
rm(packages)
#-----------------------------------------#
# 2. Run gathering and cleaning R files   #
#-----------------------------------------#
# Dynamically run R files in this order
## 2.1 Electoral data gathering
source("data_gathering/election_data_gathering.R")
## 2.2 Structural data gathering
source("data_gathering/structural_data_gathering.R")
## 2.3 Electoral data cleaning
source("data_cleaning/election_data_cleaning.R")
## 2.4 Structural data cleaning
source("data_cleaning/structural_data_cleaning.R")
#-----------------------------------------#
# 3. Merge the data                       #
#-----------------------------------------#
# Merge the data into the final data frame
Data <- merge(data.election, edu, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, refugee, "ID")
Data <- merge(Data, debt, "ID")
Data <- merge(Data, type, "ID")
# Remove used data frames
rm(data.election)
rm(edu)
rm(unemp)
rm(gdp)
rm(refugee)
rm(debt)
rm(type)
# Round all variables to 2 digits
Data[, c(12, 13, 15, 17)] <- round(as.matrix(Data[, c(12, 13, 15, 17)]), digits=2)
# Save Data as file in repository
save(Data, file = "Data_new.Rda")
View(Data)
View(Data)
View(Data)
rm(list = ls())
rm(list = ls())
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Collaborative Research Project
# Creating the Dataset
# Johannes Schulz-Knappe
# Update 17 May 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
## 1.1 Clear the environment
rm(list = ls())
## 1.2 Load packages for dataset creation
# Create vector of used packages
packages <- c('repmis', 'rvest', 'plyr', 'rio', 'xlsx')
# Install packages that are not already installed
for (p in packages) {
if (p %in% installed.packages()[,1]) require(p, character.only=TRUE)
else {
install.packages(p)
require(p, character.only=TRUE)
}
}
rm(p)
# Load packages
loaded <- lapply(packages, require, character.only = TRUE)
rm(loaded)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Final-Project',
'C:/Users/User/Documents/GitHub/Final-Project')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
## 1.4 Create bibTeX file for the used packages
LoadandCite(packages, file = 'Packages1.bib')
rm(packages)
#-----------------------------------------#
# 2. Run gathering and cleaning R files   #
#-----------------------------------------#
# Dynamically run R files in this order
## 2.1 Electoral data gathering
source("data_gathering/election_data_gathering.R")
## 2.2 Structural data gathering
source("data_gathering/structural_data_gathering.R")
## 2.3 Electoral data cleaning
source("data_cleaning/election_data_cleaning.R")
## 2.4 Structural data cleaning
source("data_cleaning/structural_data_cleaning.R")
#-----------------------------------------#
# 3. Merge the data                       #
#-----------------------------------------#
# Merge the data into the final data frame
Data <- merge(data.election, edu, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, refugee, "ID")
Data <- merge(Data, debt, "ID")
Data <- merge(Data, type, "ID")
# Remove used data frames
rm(data.election)
rm(edu)
rm(unemp)
rm(gdp)
rm(refugee)
rm(debt)
rm(type)
# Round all variables to 2 digits
Data[, c(12, 13, 15, 17)] <- round(as.matrix(Data[, c(12, 13, 15, 17)]), digits=2)
# Save Data as file in repository
save(Data, file = "Data.Rda")
View(Data)
